import Foundation
import CoreML
import UIKit
import Accelerate
import Compression
import SSZipArchive

class AIModelHandler: NSObject, FlutterStreamHandler {
    private var model: MLModel?
    private var isModelLoaded: Bool = false
    private var modnetModel: MLModel? // MODNet CoreML ëª¨ë¸
    private var realesrganX2Model: MLModel? // Real-ESRGAN x2 CoreML ëª¨ë¸
    private var methodChannel: FlutterMethodChannel?
    private var eventSink: FlutterEventSink?
    
    // ëª¨ë¸ ë‹¤ìš´ë¡œë“œ URL (ë¯¸ë¦¬ ì»´íŒŒì¼ëœ .mlmodelc íŒŒì¼)
    private let modnetURL = "https://github.com/smartcompany/models/releases/download/1.0.0/modnet.mlmodelc.zip"
    private let realesrganURL = "https://github.com/smartcompany/models/releases/download/1.0.0/realesrgan_x2plus.mlmodelc.zip"
    
    func setupChannels(methodChannel: FlutterMethodChannel, eventChannel: FlutterEventChannel) {
        self.methodChannel = methodChannel
        methodChannel.setMethodCallHandler { [weak self] (call: FlutterMethodCall, result: @escaping FlutterResult) in
            self?.handle(call: call, result: result)
        }
        eventChannel.setStreamHandler(self)
    }
    
    // FlutterStreamHandler êµ¬í˜„
    func onListen(withArguments arguments: Any?, eventSink events: @escaping FlutterEventSink) -> FlutterError? {
        self.eventSink = events
        return nil
    }
    
    func onCancel(withArguments arguments: Any?) -> FlutterError? {
        self.eventSink = nil
        return nil
    }
    
    private func sendProgress(modelName: String, progress: Double, status: String) {
        DispatchQueue.main.async {
            self.eventSink?([
                "modelName": modelName,
                "progress": progress,
                "status": status
            ])
        }
    }
    
    func handle(call: FlutterMethodCall, result: @escaping FlutterResult) {
        switch call.method {
        case "getModelStatus":
            result(isModelLoaded)
            
        case "loadModel":
            guard let args = call.arguments as? [String: Any],
                  let modelPath = args["modelPath"] as? String else {
                result(FlutterError(code: "INVALID_ARGUMENT", message: "Model path is required", details: nil))
                return
            }
            loadModel(path: modelPath, result: result)
            
        case "imageToImage":
            guard let args = call.arguments as? [String: Any] else {
                result(FlutterError(code: "INVALID_ARGUMENT", message: "Invalid arguments", details: nil))
                return
            }
            imageToImage(args: args, result: result)
            
        case "inpaint":
            guard let args = call.arguments as? [String: Any] else {
                result(FlutterError(code: "INVALID_ARGUMENT", message: "Invalid arguments", details: nil))
                return
            }
            inpaint(args: args, result: result)
            
        case "unloadModel":
            unloadModel(result: result)
            
        case "removeBackground":
            guard let args = call.arguments as? [String: Any],
                  let imagePath = args["imagePath"] as? String else {
                result(FlutterError(code: "INVALID_ARGUMENT", message: "Image path is required", details: nil))
                return
            }
            removeBackground(imagePath: imagePath, result: result)
            
        case "portraitMode":
            guard let args = call.arguments as? [String: Any],
                  let imagePath = args["imagePath"] as? String else {
                result(FlutterError(code: "INVALID_ARGUMENT", message: "Image path is required", details: nil))
                return
            }
            portraitMode(imagePath: imagePath, result: result)
            
        case "autoEnhance":
            guard let args = call.arguments as? [String: Any],
                  let imagePath = args["imagePath"] as? String else {
                result(FlutterError(code: "INVALID_ARGUMENT", message: "Image path is required", details: nil))
                return
            }
            autoEnhance(imagePath: imagePath, result: result)
            
        case "upscale":
            guard let args = call.arguments as? [String: Any],
                  let imagePath = args["imagePath"] as? String else {
                result(FlutterError(code: "INVALID_ARGUMENT", message: "Image path is required", details: nil))
                return
            }
            let scale = args["scale"] as? Int ?? 2
            upscale(imagePath: imagePath, scale: scale, result: result)
            
        case "reduceNoise":
            guard let args = call.arguments as? [String: Any],
                  let imagePath = args["imagePath"] as? String else {
                result(FlutterError(code: "INVALID_ARGUMENT", message: "Image path is required", details: nil))
                return
            }
            reduceNoise(imagePath: imagePath, result: result)
            
        case "applyFilter":
            guard let args = call.arguments as? [String: Any],
                  let imagePath = args["imagePath"] as? String,
                  let filterName = args["filterName"] as? String else {
                result(FlutterError(code: "INVALID_ARGUMENT", message: "Image path and filter name are required", details: nil))
                return
            }
            applyFilter(imagePath: imagePath, filterName: filterName, result: result)
            
        case "applyAdjustments":
            guard let args = call.arguments as? [String: Any],
                  let imagePath = args["imagePath"] as? String,
                  let adjustments = args["adjustments"] as? [String: Any] else {
                result(FlutterError(code: "INVALID_ARGUMENT", message: "Image path and adjustments are required", details: nil))
                return
            }
            applyAdjustments(imagePath: imagePath, adjustments: adjustments, result: result)
            
        default:
            result(FlutterMethodNotImplemented)
        }
    }
    
    private func loadModel(path: String, result: @escaping FlutterResult) {
        do {
            let modelURL = URL(fileURLWithPath: path)
            let config = MLModelConfiguration()
            config.computeUnits = .all // Use Neural Engine, GPU, and CPU
            
            model = try MLModel(contentsOf: modelURL, configuration: config)
            isModelLoaded = true
            result(true)
        } catch {
            print("Error loading model: \(error)")
            result(FlutterError(code: "MODEL_LOAD_ERROR", message: error.localizedDescription, details: nil))
        }
    }
    
    private func imageToImage(args: [String: Any], result: @escaping FlutterResult) {
        guard isModelLoaded, let model = model else {
            result(FlutterError(code: "MODEL_NOT_LOADED", message: "Model is not loaded", details: nil))
            return
        }
        
        guard let inputImagePath = args["inputImagePath"] as? String,
              let inputImage = UIImage(contentsOfFile: inputImagePath) else {
            result(FlutterError(code: "INVALID_IMAGE", message: "Invalid input image", details: nil))
            return
        }
        
        // TODO: Image-to-Image êµ¬í˜„
        DispatchQueue.global(qos: .userInitiated).async {
            // ì„ì‹œë¡œ ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ë°˜í™˜
            DispatchQueue.main.async {
                result(inputImagePath)
            }
        }
    }
    
    private func inpaint(args: [String: Any], result: @escaping FlutterResult) {
        guard isModelLoaded, let model = model else {
            result(FlutterError(code: "MODEL_NOT_LOADED", message: "Model is not loaded", details: nil))
            return
        }
        
        guard let inputImagePath = args["inputImagePath"] as? String,
              let maskImagePath = args["maskImagePath"] as? String else {
            result(FlutterError(code: "INVALID_ARGUMENT", message: "Input image and mask are required", details: nil))
            return
        }
        
        // TODO: Inpainting êµ¬í˜„
        DispatchQueue.global(qos: .userInitiated).async {
            // ì„ì‹œë¡œ ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ë°˜í™˜
            DispatchQueue.main.async {
                result(inputImagePath)
            }
        }
    }
    
    private func unloadModel(result: @escaping FlutterResult) {
        model = nil
        isModelLoaded = false
        result(true)
    }
    
    private func removeBackground(imagePath: String, result: @escaping FlutterResult) {
        guard let rawImage = UIImage(contentsOfFile: imagePath) else {
            result(FlutterError(code: "INVALID_IMAGE", message: "Could not load image", details: nil))
            return
        }
        
        // EXIF ë°©í–¥ ë³´ì • (íšŒì „ ë¬¸ì œ ë°©ì§€)
        guard let inputImage = fixedOrientation(rawImage) else {
            result(FlutterError(code: "IMAGE_PROCESSING_ERROR", message: "Failed to normalize image orientation", details: nil))
            return
        }
        
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                // 1. MODNet CoreML ëª¨ë¸ ë¡œë“œ (ì²˜ìŒ í•œ ë²ˆë§Œ)
                if self.modnetModel == nil {
                    // ë¡œì»¬ ëª¨ë¸ URL í™•ì¸ (Documents ë˜ëŠ” Bundle)
                    if let modelURL = self.getLocalModelURL(modelName: "modnet") {
                        do {
                            let config = MLModelConfiguration()
                            config.computeUnits = .all
                            self.modnetModel = try MLModel(contentsOf: modelURL, configuration: config)
                            print("âœ… MODNet ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                            self.continueRemoveBackground(inputImage: inputImage, result: result)
                            return
                        } catch {
                            print("âš ï¸ MODNet ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: \(error)")
                        }
                    }
                    
                    // ëª¨ë¸ì´ ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ
                    self.ensureModelDownloaded(modelName: "modnet", url: self.modnetURL) { [weak self] success in
                        guard let self = self else { return }
                        if success {
                            if let modelURL = self.getLocalModelURL(modelName: "modnet") {
                                do {
                                    let config = MLModelConfiguration()
                                    config.computeUnits = .all
                                    self.modnetModel = try MLModel(contentsOf: modelURL, configuration: config)
                                    print("âœ… MODNet ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                                    self.continueRemoveBackground(inputImage: inputImage, result: result)
                                } catch {
                                    DispatchQueue.main.async {
                                        result(FlutterError(code: "MODEL_LOAD_ERROR", message: "Failed to load MODNet model: \(error.localizedDescription)", details: nil))
                                    }
                                }
                            } else {
                                DispatchQueue.main.async {
                                    result(FlutterError(code: "MODEL_LOAD_ERROR", message: "MODNet ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", details: nil))
                                }
                            }
                        } else {
                            DispatchQueue.main.async {
                                result(FlutterError(code: "MODEL_DOWNLOAD_ERROR", message: "Failed to download MODNet model", details: nil))
                            }
                        }
                    }
                    return
                }
                
                self.continueRemoveBackground(inputImage: inputImage, result: result)
            }
        }
    }
    
    private func continueRemoveBackground(inputImage: UIImage, result: @escaping FlutterResult) {
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                guard let modnetModel = self.modnetModel else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "MODEL_LOAD_ERROR", message: "MODNet model is nil after initialization", details: nil))
                    }
                    return
                }
                
                // 2. ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (512x512 ê¸°ì¤€)
                let targetSize = CGSize(width: 512, height: 512)
                guard let resizedImage = self.resizeImage(inputImage, to: targetSize),
                      let inputArray = self.imageToInputArray(resizedImage, size: targetSize) else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "IMAGE_PROCESSING_ERROR", message: "Failed to prepare input for MODNet (image â†’ MLMultiArray)", details: nil))
                    }
                    return
                }
                
                // 3. CoreML ëª¨ë¸ ì§ì ‘ ì‹¤í–‰ (MLFeatureProvider ì‚¬ìš©)
                let inputFeature = try MLFeatureValue(multiArray: inputArray)
                let inputProvider = try MLDictionaryFeatureProvider(dictionary: ["input": inputFeature])
                let prediction = try modnetModel.prediction(from: inputProvider)
                
                // ì¶œë ¥ ì¶”ì¶œ (ëª¨ë¸ì˜ ì¶œë ¥ ì´ë¦„ í™•ì¸ í•„ìš”, ì¼ë°˜ì ìœ¼ë¡œ "output")
                guard let outputFeature = prediction.featureValue(for: "output"),
                      let maskArray = outputFeature.multiArrayValue else {
                    throw NSError(domain: "ModelError", code: -1, userInfo: [NSLocalizedDescriptionKey: "ëª¨ë¸ ì¶œë ¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"])
                }
                
                // 4. MLMultiArray -> ë§ˆìŠ¤í¬ UIImage ë³€í™˜
                guard let rawMaskImage = self.multiArrayToMaskImage(maskArray) else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "MODEL_PREDICTION_ERROR", message: "Failed to convert MODNet output to mask image", details: nil))
                    }
                    return
                }
                
                // 5. ë§ˆìŠ¤í¬ë¥¼ ì›ë³¸ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ í›„ ì ìš©
                guard let resizedMask = self.resizeImage(rawMaskImage, to: inputImage.size),
                      let resultImage = self.applyMask(inputImage, mask: resizedMask) else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "IMAGE_PROCESSING_ERROR", message: "Failed to apply MODNet mask to image", details: nil))
                    }
                    return
                }
                
                // 6. ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
                let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
                let outputPath = documentsPath.appendingPathComponent("removed_bg_\(UUID().uuidString).png")
                
                guard let imageData = resultImage.pngData() else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "IMAGE_SAVE_ERROR", message: "Failed to convert result image to PNG", details: nil))
                    }
                    return
                }
                
                try imageData.write(to: outputPath)
                
                DispatchQueue.main.async {
                    result(outputPath.path)
                }
                
            } catch {
                print("âŒ MODNet CoreML prediction failed: \(error)")
                let nsError = error as NSError
                print("  domain: \(nsError.domain)")
                print("  code: \(nsError.code)")
                print("  userInfo: \(nsError.userInfo)")
                
                DispatchQueue.main.async {
                    result(
                        FlutterError(
                            code: "MODEL_PREDICTION_ERROR",
                            message: "Failed to run MODNet prediction: \(error)",
                            details: nsError.userInfo
                        )
                    )
                }
            }
        }
    }
    
    // UIImage -> MODNet ì…ë ¥ìš© MLMultiArray (shape: [1, 3, H, W], 0~1 normalize)
    private func imageToInputArray(_ image: UIImage, size: CGSize) -> MLMultiArray? {
        guard let cgImage = image.cgImage else { return nil }
        
        let width = Int(size.width)
        let height = Int(size.height)
        let channels = 3
        
        // 1x3xHxW
        guard let array = try? MLMultiArray(
            shape: [1, NSNumber(value: channels), NSNumber(value: height), NSNumber(value: width)],
            dataType: .float32
        ) else {
            return nil
        }
        
        // RGBA 8ë¹„íŠ¸ ë²„í¼ì— ì´ë¯¸ì§€ ê·¸ë¦¬ê¸°
        let bytesPerPixel = 4
        let bytesPerRow = bytesPerPixel * width
        let bitsPerComponent = 8
        var rawData = [UInt8](repeating: 0, count: width * height * bytesPerPixel)
        
        guard let context = CGContext(
            data: &rawData,
            width: width,
            height: height,
            bitsPerComponent: bitsPerComponent,
            bytesPerRow: bytesPerRow,
            space: CGColorSpaceCreateDeviceRGB(),
            bitmapInfo: CGImageAlphaInfo.premultipliedLast.rawValue
        ) else {
            return nil
        }
        
        context.interpolationQuality = .high
        context.draw(cgImage, in: CGRect(origin: .zero, size: size))
        
        // RGBA â†’ NCHW(Float32) [0,1] ì •ê·œí™”
        let ptr = UnsafeMutablePointer<Float32>(OpaquePointer(array.dataPointer))
        
        func index(n: Int, c: Int, h: Int, w: Int) -> Int {
            // n * (C*H*W) + c * (H*W) + h * W + w
            return n * (channels * height * width) + c * (height * width) + h * width + w
        }
        
        for h in 0..<height {
            for w in 0..<width {
                let pixelIndex = h * bytesPerRow + w * bytesPerPixel
                let r = Float32(rawData[pixelIndex]) / 255.0
                let g = Float32(rawData[pixelIndex + 1]) / 255.0
                let b = Float32(rawData[pixelIndex + 2]) / 255.0
                
                ptr[index(n: 0, c: 0, h: h, w: w)] = r
                ptr[index(n: 0, c: 1, h: h, w: w)] = g
                ptr[index(n: 0, c: 2, h: h, w: w)] = b
            }
        }
        
        return array
    }
    
    // UIImage ë°©í–¥ì„ í•­ìƒ .up ìœ¼ë¡œ ë³´ì • (EXIF íšŒì „ ì œê±°)
    // íšŒì „ëœ ê²°ê³¼ê°€ ë‚˜ì˜¤ëŠ” ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©
    private func fixedOrientation(_ image: UIImage) -> UIImage? {
        if image.imageOrientation == .up {
            return image
        }
        
        UIGraphicsBeginImageContextWithOptions(image.size, false, image.scale)
        defer { UIGraphicsEndImageContext() }
        
        image.draw(in: CGRect(origin: .zero, size: image.size))
        return UIGraphicsGetImageFromCurrentImageContext()
    }

    // MLMultiArray (0~1 ê°’ì˜ ë§ˆìŠ¤í¬) -> ê·¸ë ˆì´ìŠ¤ì¼€ì¼ UIImageë¡œ ë³€í™˜
    private func multiArrayToMaskImage(_ array: MLMultiArray) -> UIImage? {
        // shape ì˜ˆ: [1, 1, H, W] ë˜ëŠ” [1, H, W, 1]
        let shape = array.shape.map { $0.intValue }
        guard shape.count >= 2 else { return nil }
        
        let height: Int
        let width: Int
        if shape.count == 2 {
            height = shape[0]
            width = shape[1]
        } else {
            // ë§ˆì§€ë§‰ ë‘ ì°¨ì›ì„ H, Wë¡œ ê°€ì •
            height = shape[shape.count - 2]
            width = shape[shape.count - 1]
        }
        
        let count = width * height
        guard count > 0 else { return nil }
        
        // Float32 ë°°ì—´ë¡œ ê°€ì • (coremltools ê¸°ë³¸)
        let ptr = UnsafeMutablePointer<Float32>(OpaquePointer(array.dataPointer))
        var pixels = [UInt8](repeating: 0, count: count)
        
        for i in 0..<count {
            let v = ptr[i]
            let clamped = max(0.0, min(1.0, Float(v)))
            pixels[i] = UInt8(clamped * 255.0)
        }
        
        let colorSpace = CGColorSpaceCreateDeviceGray()
        guard let context = CGContext(
            data: &pixels,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: width,
            space: colorSpace,
            bitmapInfo: 0
        ) else {
            return nil
        }
        
        guard let cgImage = context.makeImage() else { return nil }
        return UIImage(cgImage: cgImage)
    }
    
    // MLMultiArray (NCHW í˜•ì‹, RGB) -> UIImage ë³€í™˜
    // shape: [1, 3, H, W] ë˜ëŠ” [1, C, H, W]
    private func multiArrayToRGBImage(_ array: MLMultiArray) -> UIImage? {
        let shape = array.shape.map { $0.intValue }
        print("ğŸ“‹ MultiArray shape: \(shape)")
        
        guard shape.count == 4 else {
            print("âŒ ì˜ˆìƒí•˜ì§€ ëª»í•œ shape: \(shape)")
            return nil
        }
        
        // NCHW í˜•ì‹: [ë°°ì¹˜, ì±„ë„, ë†’ì´, ë„ˆë¹„]
        let batch = shape[0]
        let channels = shape[1]
        let height = shape[2]
        let width = shape[3]
        
        guard batch == 1, channels == 3 else {
            print("âŒ ì˜ˆìƒí•˜ì§€ ëª»í•œ ë°°ì¹˜/ì±„ë„: batch=\(batch), channels=\(channels)")
            return nil
        }
        
        let pixelCount = width * height
        guard pixelCount > 0 else { return nil }
        
        // Float32 ë°°ì—´ë¡œ ê°€ì •
        let ptr = UnsafeMutablePointer<Float32>(OpaquePointer(array.dataPointer))
        
        // RGBA í”½ì…€ ë°ì´í„° ìƒì„±
        var pixels = [UInt8](repeating: 0, count: pixelCount * 4)
        
        // NCHW -> RGBA ë³€í™˜
        // ì¸ë±ìŠ¤ ê³„ì‚°: n * (C*H*W) + c * (H*W) + h * W + w
        for h in 0..<height {
            for w in 0..<width {
                let pixelIndex = (h * width + w) * 4
                
                // R, G, B ì±„ë„ ì½ê¸°
                let rIndex = 0 * (height * width) + h * width + w
                let gIndex = 1 * (height * width) + h * width + w
                let bIndex = 2 * (height * width) + h * width + w
                
                // 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”ëœ ê°’ì´ë¼ê³  ê°€ì •í•˜ê³  0-255ë¡œ ë³€í™˜
                let r = max(0.0, min(1.0, Double(ptr[rIndex])))
                let g = max(0.0, min(1.0, Double(ptr[gIndex])))
                let b = max(0.0, min(1.0, Double(ptr[bIndex])))
                
                pixels[pixelIndex] = UInt8(r * 255.0)     // R
                pixels[pixelIndex + 1] = UInt8(g * 255.0) // G
                pixels[pixelIndex + 2] = UInt8(b * 255.0) // B
                pixels[pixelIndex + 3] = 255               // A (ë¶ˆíˆ¬ëª…)
            }
        }
        
        // CGContextë¡œ ì´ë¯¸ì§€ ìƒì„±
        let colorSpace = CGColorSpaceCreateDeviceRGB()
        guard let context = CGContext(
            data: &pixels,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: width * 4,
            space: colorSpace,
            bitmapInfo: CGImageAlphaInfo.premultipliedLast.rawValue
        ) else {
            return nil
        }
        
        guard let cgImage = context.makeImage() else { return nil }
        return UIImage(cgImage: cgImage)
    }
    
    // ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ í—¬í¼ í•¨ìˆ˜
    private func resizeImage(_ image: UIImage, to size: CGSize) -> UIImage? {
        UIGraphicsBeginImageContextWithOptions(size, false, image.scale)
        defer { UIGraphicsEndImageContext() }
        
        image.draw(in: CGRect(origin: .zero, size: size))
        return UIGraphicsGetImageFromCurrentImageContext()
    }
    
    // UIImageë¥¼ CVPixelBufferë¡œ ë³€í™˜
    private func imageToPixelBuffer(_ image: UIImage, size: CGSize) -> CVPixelBuffer? {
        let attrs = [
            kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue!,
            kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue!
        ] as CFDictionary
        
        var pixelBuffer: CVPixelBuffer?
        let status = CVPixelBufferCreate(
            kCFAllocatorDefault,
            Int(size.width),
            Int(size.height),
            kCVPixelFormatType_32ARGB,
            attrs,
            &pixelBuffer
        )
        
        guard status == kCVReturnSuccess, let buffer = pixelBuffer else {
            return nil
        }
        
        CVPixelBufferLockBaseAddress(buffer, [])
        defer { CVPixelBufferUnlockBaseAddress(buffer, []) }
        
        let colorSpace = CGColorSpaceCreateDeviceRGB()
        guard let context = CGContext(
            data: CVPixelBufferGetBaseAddress(buffer),
            width: Int(size.width),
            height: Int(size.height),
            bitsPerComponent: 8,
            bytesPerRow: CVPixelBufferGetBytesPerRow(buffer),
            space: colorSpace,
            bitmapInfo: CGImageAlphaInfo.noneSkipFirst.rawValue
        ) else {
            return nil
        }
        
        guard let cgImage = image.cgImage else {
            return nil
        }
        
        context.draw(cgImage, in: CGRect(origin: .zero, size: size))
        
        return buffer
    }
    
    // CVPixelBufferë¥¼ UIImageë¡œ ë³€í™˜
    private func pixelBufferToImage(_ pixelBuffer: CVPixelBuffer) -> UIImage? {
        let ciImage = CIImage(cvPixelBuffer: pixelBuffer)
        let context = CIContext()
        guard let cgImage = context.createCGImage(ciImage, from: ciImage.extent) else {
            return nil
        }
        return UIImage(cgImage: cgImage)
    }
    
    // ë§ˆìŠ¤í¬ë¥¼ ì ìš©í•˜ì—¬ ë°°ê²½ ì œê±°
    private func applyMask(_ image: UIImage, mask: UIImage) -> UIImage? {
        guard let imageCG = image.cgImage,
              let maskCG = mask.cgImage else {
            return nil
        }
        
        let width = imageCG.width
        let height = imageCG.height
        let colorSpace = CGColorSpaceCreateDeviceRGB()
        
        // ë§ˆìŠ¤í¬ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
        guard let maskContext = CGContext(
            data: nil,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: width,
            space: CGColorSpaceCreateDeviceGray(),
            bitmapInfo: CGImageAlphaInfo.none.rawValue
        ) else {
            return nil
        }
        
        maskContext.draw(maskCG, in: CGRect(x: 0, y: 0, width: width, height: height))
        guard let grayMask = maskContext.makeImage() else {
            return nil
        }
        
        // ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± (íˆ¬ëª… ë°°ê²½)
        guard let context = CGContext(
            data: nil,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: width * 4,
            space: colorSpace,
            bitmapInfo: CGImageAlphaInfo.premultipliedLast.rawValue
        ) else {
            return nil
        }
        
        // ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë¦¬í•‘
        context.clip(to: CGRect(x: 0, y: 0, width: width, height: height), mask: grayMask)
        
        // ì›ë³¸ ì´ë¯¸ì§€ ê·¸ë¦¬ê¸°
        context.draw(imageCG, in: CGRect(x: 0, y: 0, width: width, height: height))
        
        guard let resultCG = context.makeImage() else {
            return nil
        }
        
        return UIImage(cgImage: resultCG)
    }
    
    // MARK: - Portrait Mode (GFPGAN/CodeFormer)
    private func portraitMode(imagePath: String, result: @escaping FlutterResult) {
        guard let image = UIImage(contentsOfFile: imagePath) else {
            result(FlutterError(code: "INVALID_IMAGE", message: "Could not load image", details: nil))
            return
        }
        
        DispatchQueue.global(qos: .userInitiated).async {
            // TODO: GFPGAN CoreML ëª¨ë¸ ë¡œë“œ ë° ì‹¤í–‰
            // í˜„ì¬ëŠ” ê°„ë‹¨í•œ í•„í„°ë¡œ ì–¼êµ´ ë³´ì • íš¨ê³¼ ì ìš©
            guard let correctedImage = self.fixedOrientation(image) else {
                DispatchQueue.main.async {
                    result(FlutterError(code: "IMAGE_PROCESSING_ERROR", message: "Failed to correct image orientation", details: nil))
                }
                return
            }
            let processedImage = self.applyPortraitFilter(correctedImage)
            
            guard let outputPath = self.saveImage(processedImage, prefix: "portrait") else {
                DispatchQueue.main.async {
                    result(FlutterError(code: "SAVE_ERROR", message: "Failed to save processed image", details: nil))
                }
                return
            }
            
            DispatchQueue.main.async {
                result(outputPath)
            }
        }
    }
    
    // Portrait Mode í•„í„° ì ìš© (ì„ì‹œ êµ¬í˜„)
    private func applyPortraitFilter(_ image: UIImage) -> UIImage {
        guard let ciImage = CIImage(image: image) else { return image }
        
        let context = CIContext()
        
        // ë¶€ë“œëŸ¬ìš´ ë¸”ëŸ¬ + ì„ ëª…ë„ ì¡°ì •ìœ¼ë¡œ í”¼ë¶€ ë³´ì • íš¨ê³¼
        guard let blurFilter = CIFilter(name: "CIGaussianBlur") else { return image }
        blurFilter.setValue(ciImage, forKey: kCIInputImageKey)
        blurFilter.setValue(3.0, forKey: kCIInputRadiusKey)
        guard let blurredImage = blurFilter.outputImage else { return image }
        
        guard let sharpenFilter = CIFilter(name: "CIUnsharpMask") else { return image }
        sharpenFilter.setValue(ciImage, forKey: kCIInputImageKey)
        sharpenFilter.setValue(2.0, forKey: kCIInputRadiusKey)
        sharpenFilter.setValue(2.0, forKey: kCIInputIntensityKey)
        guard let sharpenedImage = sharpenFilter.outputImage else { return image }
        
        // ë¸”ëŸ¬ì™€ ì„ ëª…ë„ë¥¼ ë¸”ë Œë”©
        guard let blendFilter = CIFilter(name: "CISourceOverCompositing") else { return image }
        blendFilter.setValue(blurredImage, forKey: kCIInputImageKey)
        blendFilter.setValue(sharpenedImage, forKey: kCIInputBackgroundImageKey)
        guard let blendedImage = blendFilter.outputImage else { return image }
        
        guard let cgImage = context.createCGImage(blendedImage, from: ciImage.extent) else {
            return image
        }
        
        return UIImage(cgImage: cgImage)
    }
    
    // MARK: - Auto Enhance (Real-ESRGAN)
    private func autoEnhance(imagePath: String, result: @escaping FlutterResult) {
        guard let image = UIImage(contentsOfFile: imagePath) else {
            result(FlutterError(code: "INVALID_IMAGE", message: "Could not load image", details: nil))
            return
        }
        
        DispatchQueue.global(qos: .userInitiated).async {
            guard let correctedImage = self.fixedOrientation(image) else {
                DispatchQueue.main.async {
                    result(FlutterError(code: "IMAGE_PROCESSING_ERROR", message: "Failed to correct image orientation", details: nil))
                }
                return
            }
            
            // Real-ESRGAN x2 ëª¨ë¸ ë¡œë“œ ë° ë‹¤ìš´ë¡œë“œ í™•ì¸
            self.loadRealESRGANModel { [weak self] success in
                guard let self = self, success else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "MODEL_LOAD_ERROR", message: "Failed to load Real-ESRGAN model for auto enhance", details: nil))
                    }
                    return
                }
                
                // Real-ESRGAN x2 ëª¨ë¸ ì‚¬ìš© (í–¥ìƒ í›„ ì›ë³¸ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ)
                guard let processedImage = self.runRealESRGAN(correctedImage, scale: 2) else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "MODEL_EXECUTION_ERROR", message: "Failed to execute Real-ESRGAN model", details: nil))
                    }
                    return
                }
                
                // ì›ë³¸ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (í–¥ìƒë§Œ í•˜ê³  í¬ê¸°ëŠ” ìœ ì§€)
                let originalSize = correctedImage.size
                guard let resizedImage = self.resizeImage(processedImage, to: originalSize) else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "IMAGE_PROCESSING_ERROR", message: "Failed to resize enhanced image", details: nil))
                    }
                    return
                }
                
                guard let outputPath = self.saveImage(resizedImage, prefix: "enhanced") else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "SAVE_ERROR", message: "Failed to save processed image", details: nil))
                    }
                    return
                }
                
                DispatchQueue.main.async {
                    result(outputPath)
                }
            }
        }
    }
    
    // MARK: - Upscale (Real-ESRGAN)
    private func upscale(imagePath: String, scale: Int, result: @escaping FlutterResult) {
        guard let image = UIImage(contentsOfFile: imagePath) else {
            result(FlutterError(code: "INVALID_IMAGE", message: "Could not load image", details: nil))
            return
        }
        
        guard scale >= 2 && scale <= 4 else {
            result(FlutterError(code: "INVALID_SCALE", message: "Scale must be between 2 and 4", details: nil))
            return
        }
        
        DispatchQueue.global(qos: .userInitiated).async {
            guard let correctedImage = self.fixedOrientation(image) else {
                DispatchQueue.main.async {
                    result(FlutterError(code: "IMAGE_PROCESSING_ERROR", message: "Failed to correct image orientation", details: nil))
                }
                return
            }
            
            // Real-ESRGAN x2 ëª¨ë¸ ë¡œë“œ ë° ë‹¤ìš´ë¡œë“œ í™•ì¸
            self.loadRealESRGANModel { [weak self] success in
                guard let self = self, success else {
                    // ëª¨ë¸ì´ ì—†ìœ¼ë©´ í•„í„° í´ë°±
                    let processedImage = self?.applyUpscaleFilter(correctedImage, scale: scale) ?? correctedImage
                    guard let outputPath = self?.saveImage(processedImage, prefix: "upscale_x\(scale)") else {
                        DispatchQueue.main.async {
                            result(FlutterError(code: "SAVE_ERROR", message: "Failed to save processed image", details: nil))
                        }
                        return
                    }
                    
                    DispatchQueue.main.async {
                        result(outputPath)
                    }
                    return
                }
                
                // Real-ESRGAN x2 ëª¨ë¸ ì‚¬ìš©
                // scale=2: x2 ëª¨ë¸ 1ë²ˆ ì ìš©
                // scale=4: x2 ëª¨ë¸ 2ë²ˆ ì ìš© (x2 * x2 = x4)
                if scale == 2 {
                    if let processedImage = self.runRealESRGAN(correctedImage, scale: 2) {
                        guard let outputPath = self.saveImage(processedImage, prefix: "upscale_x2") else {
                            DispatchQueue.main.async {
                                result(FlutterError(code: "SAVE_ERROR", message: "Failed to save processed image", details: nil))
                            }
                            return
                        }
                        
                        DispatchQueue.main.async {
                            result(outputPath)
                        }
                        return
                    }
                } else if scale == 4 {
                    // x2 ëª¨ë¸ì„ 2ë²ˆ ì ìš©í•˜ì—¬ x4 íš¨ê³¼
                    if let firstUpscale = self.runRealESRGAN(correctedImage, scale: 2),
                       let secondUpscale = self.runRealESRGAN(firstUpscale, scale: 2) {
                        guard let outputPath = self.saveImage(secondUpscale, prefix: "upscale_x4") else {
                            DispatchQueue.main.async {
                                result(FlutterError(code: "SAVE_ERROR", message: "Failed to save processed image", details: nil))
                            }
                            return
                        }
                        
                        DispatchQueue.main.async {
                            result(outputPath)
                        }
                        return
                    }
                }
                
                // ëª¨ë¸ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ í•„í„° í´ë°±
                let processedImage = self.applyUpscaleFilter(correctedImage, scale: scale)
                guard let outputPath = self.saveImage(processedImage, prefix: "upscale_x\(scale)") else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "SAVE_ERROR", message: "Failed to save processed image", details: nil))
                    }
                    return
                }
                
                DispatchQueue.main.async {
                    result(outputPath)
                }
            }
        }
    }
    
    // Upscale í•„í„° ì ìš© (ì„ì‹œ êµ¬í˜„)
    private func applyUpscaleFilter(_ image: UIImage, scale: Int) -> UIImage {
        let newSize = CGSize(
            width: image.size.width * CGFloat(scale),
            height: image.size.height * CGFloat(scale)
        )
        
        UIGraphicsBeginImageContextWithOptions(newSize, false, image.scale)
        defer { UIGraphicsEndImageContext() }
        
        image.draw(in: CGRect(origin: .zero, size: newSize))
        
        guard let upscaledImage = UIGraphicsGetImageFromCurrentImageContext() else {
            return image
        }
        
        return upscaledImage
    }
    
    // MARK: - Reduce Noise (Real-ESRGAN)
    private func reduceNoise(imagePath: String, result: @escaping FlutterResult) {
        guard let image = UIImage(contentsOfFile: imagePath) else {
            result(FlutterError(code: "INVALID_IMAGE", message: "Could not load image", details: nil))
            return
        }
        
        DispatchQueue.global(qos: .userInitiated).async {
            guard let correctedImage = self.fixedOrientation(image) else {
                DispatchQueue.main.async {
                    result(FlutterError(code: "IMAGE_PROCESSING_ERROR", message: "Failed to correct image orientation", details: nil))
                }
                return
            }
            
            // Real-ESRGAN x2 ëª¨ë¸ ë¡œë“œ ë° ë‹¤ìš´ë¡œë“œ í™•ì¸
            self.loadRealESRGANModel { [weak self] success in
                guard let self = self, success else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "MODEL_LOAD_ERROR", message: "Failed to load Real-ESRGAN model for reduce noise", details: nil))
                    }
                    return
                }
                
                // Real-ESRGAN x2 ëª¨ë¸ ì‚¬ìš©
                guard let processedImage = self.runRealESRGAN(correctedImage, scale: 2) else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "MODEL_EXECUTION_ERROR", message: "Failed to execute Real-ESRGAN model", details: nil))
                    }
                    return
                }
                
                // ì›ë³¸ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ë…¸ì´ì¦ˆ ì œê±°ë§Œ í•˜ê³  í¬ê¸°ëŠ” ìœ ì§€)
                let originalSize = correctedImage.size
                guard let resizedImage = self.resizeImage(processedImage, to: originalSize) else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "IMAGE_PROCESSING_ERROR", message: "Failed to resize denoised image", details: nil))
                    }
                    return
                }
                
                guard let outputPath = self.saveImage(resizedImage, prefix: "denoise") else {
                    DispatchQueue.main.async {
                        result(FlutterError(code: "SAVE_ERROR", message: "Failed to save processed image", details: nil))
                    }
                    return
                }
                
                DispatchQueue.main.async {
                    result(outputPath)
                }
            }
        }
    }
    
    // MARK: - Apply Filter
    private func applyFilter(imagePath: String, filterName: String, result: @escaping FlutterResult) {
        guard let image = UIImage(contentsOfFile: imagePath) else {
            result(FlutterError(code: "INVALID_IMAGE", message: "Could not load image", details: nil))
            return
        }
        
        DispatchQueue.global(qos: .userInitiated).async {
            guard let correctedImage = self.fixedOrientation(image) else {
                DispatchQueue.main.async {
                    result(FlutterError(code: "IMAGE_PROCESSING_ERROR", message: "Failed to correct image orientation", details: nil))
                }
                return
            }
            
            let filteredImage = self.applyImageFilter(correctedImage, filterName: filterName)
            
            guard let outputPath = self.saveImage(filteredImage, prefix: "filtered_\(filterName.lowercased())") else {
                DispatchQueue.main.async {
                    result(FlutterError(code: "SAVE_ERROR", message: "Failed to save filtered image", details: nil))
                }
                return
            }
            
            DispatchQueue.main.async {
                result(outputPath)
            }
        }
    }
    
    private func applyImageFilter(_ image: UIImage, filterName: String) -> UIImage {
        guard let ciImage = CIImage(image: image) else { return image }
        let context = CIContext()
        
        var outputImage: CIImage = ciImage
        
        switch filterName.lowercased() {
        case "original", "none":
            // ì›ë³¸ ê·¸ëŒ€ë¡œ
            break
            
        case "vivid":
            // ë¹„ë¹„ë“œ: ì±„ë„ì™€ ëŒ€ë¹„ ì¦ê°€
            if let colorControls = CIFilter(name: "CIColorControls") {
                colorControls.setValue(ciImage, forKey: kCIInputImageKey)
                colorControls.setValue(1.3, forKey: kCIInputSaturationKey)
                colorControls.setValue(1.15, forKey: kCIInputContrastKey)
                if let vividImage = colorControls.outputImage {
                    outputImage = vividImage
                }
            }
            
        case "vintage":
            // ë¹ˆí‹°ì§€ íš¨ê³¼: ì„¸í”¼ì•„ + ì•½ê°„ì˜ ë…¸ì´ì¦ˆ
            if let sepiaFilter = CIFilter(name: "CISepiaTone") {
                sepiaFilter.setValue(ciImage, forKey: kCIInputImageKey)
                sepiaFilter.setValue(0.8, forKey: kCIInputIntensityKey)
                if let sepiaImage = sepiaFilter.outputImage {
                    outputImage = sepiaImage
                }
            }
            
        case "b&w", "black & white", "black and white":
            // í‘ë°±: ì±„ë„ 0
            if let colorControls = CIFilter(name: "CIColorControls") {
                colorControls.setValue(ciImage, forKey: kCIInputImageKey)
                colorControls.setValue(0.0, forKey: kCIInputSaturationKey)
                if let bwImage = colorControls.outputImage {
                    outputImage = bwImage
                }
            }
            
        case "cool":
            // ì¿¨ í†¤: ìƒ‰ì˜¨ë„ ì¡°ì • (íŒŒë€ìƒ‰ í†¤)
            if let temperatureFilter = CIFilter(name: "CITemperatureAndTint") {
                temperatureFilter.setValue(ciImage, forKey: kCIInputImageKey)
                temperatureFilter.setValue(CIVector(x: 6500, y: 0), forKey: "inputNeutral")
                temperatureFilter.setValue(CIVector(x: 8000, y: 0), forKey: "inputTargetNeutral")
                if let coolImage = temperatureFilter.outputImage {
                    outputImage = coolImage
                }
            } else {
                // ëŒ€ì²´: ìƒ‰ì¡° ì¡°ì •
                if let colorControls = CIFilter(name: "CIColorControls") {
                    colorControls.setValue(ciImage, forKey: kCIInputImageKey)
                    colorControls.setValue(0.9, forKey: kCIInputSaturationKey)
                    if let coolImage = colorControls.outputImage {
                        outputImage = coolImage
                    }
                }
            }
            
        case "warm":
            // ì›œ í†¤: ìƒ‰ì˜¨ë„ ì¡°ì • (ì£¼í™©ìƒ‰ í†¤)
            if let temperatureFilter = CIFilter(name: "CITemperatureAndTint") {
                temperatureFilter.setValue(ciImage, forKey: kCIInputImageKey)
                temperatureFilter.setValue(CIVector(x: 6500, y: 0), forKey: "inputNeutral")
                temperatureFilter.setValue(CIVector(x: 4500, y: 0), forKey: "inputTargetNeutral")
                if let warmImage = temperatureFilter.outputImage {
                    outputImage = warmImage
                }
            } else {
                // ëŒ€ì²´: ìƒ‰ì¡° ì¡°ì •
                if let colorControls = CIFilter(name: "CIColorControls") {
                    colorControls.setValue(ciImage, forKey: kCIInputImageKey)
                    colorControls.setValue(1.1, forKey: kCIInputSaturationKey)
                    colorControls.setValue(1.05, forKey: kCIInputBrightnessKey)
                    if let warmImage = colorControls.outputImage {
                        outputImage = warmImage
                    }
                }
            }
            
        case "dramatic":
            // ë“œë¼ë§ˆí‹±: ëŒ€ë¹„ ì¦ê°€ + ì•½ê°„ì˜ ì±„ë„ ì¦ê°€
            if let colorControls = CIFilter(name: "CIColorControls") {
                colorControls.setValue(ciImage, forKey: kCIInputImageKey)
                colorControls.setValue(1.3, forKey: kCIInputContrastKey)
                colorControls.setValue(1.1, forKey: kCIInputSaturationKey)
                if let dramaticImage = colorControls.outputImage {
                    outputImage = dramaticImage
                }
            }
            
        case "cinematic":
            // ì‹œë„¤ë§ˆí‹±: ëŒ€ë¹„ ì¦ê°€ + ìƒ‰ì¡° ì¡°ì •
            if let colorControls = CIFilter(name: "CIColorControls") {
                colorControls.setValue(ciImage, forKey: kCIInputImageKey)
                colorControls.setValue(1.2, forKey: kCIInputContrastKey)
                colorControls.setValue(0.95, forKey: kCIInputBrightnessKey)
                if let cinematicImage = colorControls.outputImage {
                    outputImage = cinematicImage
                }
            }
            
        case "mono":
            // ëª¨ë…¸: í‘ë°± ë³€í™˜ (B&Wì™€ ë™ì¼)
            if let colorControls = CIFilter(name: "CIColorControls") {
                colorControls.setValue(ciImage, forKey: kCIInputImageKey)
                colorControls.setValue(0.0, forKey: kCIInputSaturationKey)
                if let monoImage = colorControls.outputImage {
                    outputImage = monoImage
                }
            }
            
        case "silver":
            // ì‹¤ë²„: í‘ë°± + ì•½ê°„ì˜ ë°ê¸° ì¦ê°€
            if let colorControls = CIFilter(name: "CIColorControls") {
                colorControls.setValue(ciImage, forKey: kCIInputImageKey)
                colorControls.setValue(0.0, forKey: kCIInputSaturationKey)
                colorControls.setValue(1.1, forKey: kCIInputBrightnessKey)
                if let silverImage = colorControls.outputImage {
                    outputImage = silverImage
                }
            }
            
        case "noir":
            // ëˆ„ì•„ë¥´: í‘ë°± + ëŒ€ë¹„ ì¦ê°€ + ì•½ê°„ì˜ ì–´ë‘¡ê²Œ
            if let colorControls = CIFilter(name: "CIColorControls") {
                colorControls.setValue(ciImage, forKey: kCIInputImageKey)
                colorControls.setValue(0.0, forKey: kCIInputSaturationKey)
                colorControls.setValue(1.3, forKey: kCIInputContrastKey)
                colorControls.setValue(0.9, forKey: kCIInputBrightnessKey)
                if let noirImage = colorControls.outputImage {
                    outputImage = noirImage
                }
            }
            
        default:
            // ì•Œ ìˆ˜ ì—†ëŠ” í•„í„°ëŠ” ì›ë³¸ ë°˜í™˜
            break
        }
        
        guard let cgImage = context.createCGImage(outputImage, from: outputImage.extent) else {
            return image
        }
        
        return UIImage(cgImage: cgImage)
    }
    
    // MARK: - Apply Adjustments
    private func applyAdjustments(imagePath: String, adjustments: [String: Any], result: @escaping FlutterResult) {
        guard let image = UIImage(contentsOfFile: imagePath) else {
            result(FlutterError(code: "INVALID_IMAGE", message: "Could not load image", details: nil))
            return
        }
        
        DispatchQueue.global(qos: .userInitiated).async {
            guard let correctedImage = self.fixedOrientation(image) else {
                DispatchQueue.main.async {
                    result(FlutterError(code: "IMAGE_PROCESSING_ERROR", message: "Failed to correct image orientation", details: nil))
                }
                return
            }
            
            let adjustedImage = self.applyImageAdjustments(correctedImage, adjustments: adjustments)
            
            guard let outputPath = self.saveImage(adjustedImage, prefix: "adjusted") else {
                DispatchQueue.main.async {
                    result(FlutterError(code: "SAVE_ERROR", message: "Failed to save adjusted image", details: nil))
                }
                return
            }
            
            DispatchQueue.main.async {
                result(outputPath)
            }
        }
    }
    
    private func applyImageAdjustments(_ image: UIImage, adjustments: [String: Any]) -> UIImage {
        guard let ciImage = CIImage(image: image) else { return image }
        let context = CIContext()
        
        let originalExtent = ciImage.extent
        var outputImage: CIImage = ciImage
        
        // Brightness, Contrast, Saturation ì¡°ì •
        if let colorControls = CIFilter(name: "CIColorControls") {
            colorControls.setValue(outputImage, forKey: kCIInputImageKey)
            
            // ê¸°ë³¸ê°’ ì„¤ì • (ë³€ê²½ë˜ì§€ ì•Šì€ ê°’ë„ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •)
            let brightness = (adjustments["brightness"] as? Double) ?? 0.0
            let contrast = (adjustments["contrast"] as? Double) ?? 0.0
            let saturation = (adjustments["saturation"] as? Double) ?? 0.0
            
            // CIColorControlsì˜ ë²”ìœ„:
            // Brightness: -1.0 ~ 1.0 (ê¸°ë³¸ê°’ 0.0)
            // Contrast: 0.0 ~ 4.0 (ê¸°ë³¸ê°’ 1.0)
            // Saturation: 0.0 ~ 2.0 (ê¸°ë³¸ê°’ 1.0)
            
            colorControls.setValue(NSNumber(value: brightness), forKey: kCIInputBrightnessKey)
            colorControls.setValue(NSNumber(value: 1.0 + contrast), forKey: kCIInputContrastKey) // contrast: -1~1 -> 0~2
            colorControls.setValue(NSNumber(value: 1.0 + saturation), forKey: kCIInputSaturationKey) // saturation: -1~1 -> 0~2
            
            if let adjustedImage = colorControls.outputImage {
                outputImage = adjustedImage
            }
        }
        
        // Blur ì ìš©
        if let blurValue = adjustments["blur"] as? Double, blurValue > 0 {
            if let blurFilter = CIFilter(name: "CIGaussianBlur") {
                blurFilter.setValue(outputImage, forKey: kCIInputImageKey)
                blurFilter.setValue(NSNumber(value: blurValue), forKey: kCIInputRadiusKey)
                if let blurredImage = blurFilter.outputImage {
                    outputImage = blurredImage
                }
            }
        }
        
        // Sharpen ì ìš©
        if let sharpenValue = adjustments["sharpen"] as? Double, sharpenValue > 0 {
            if let sharpenFilter = CIFilter(name: "CIUnsharpMask") {
                sharpenFilter.setValue(outputImage, forKey: kCIInputImageKey)
                sharpenFilter.setValue(NSNumber(value: 2.5), forKey: kCIInputRadiusKey) // ë°˜ê²½
                sharpenFilter.setValue(NSNumber(value: sharpenValue), forKey: kCIInputIntensityKey) // ê°•ë„
                if let sharpenedImage = sharpenFilter.outputImage {
                    outputImage = sharpenedImage
                }
            }
        }
        
        // extentë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì œí•œ (blurë¡œ ì¸í•œ ë¬´í•œëŒ€ extent ë°©ì§€)
        let finalExtent = outputImage.extent.isInfinite ? originalExtent : outputImage.extent.intersection(originalExtent)
        
        guard let cgImage = context.createCGImage(outputImage, from: finalExtent) else {
            print("âŒ CGImage ìƒì„± ì‹¤íŒ¨")
            return image
        }
        
        return UIImage(cgImage: cgImage)
    }
    
    // MARK: - Real-ESRGAN CoreML ëª¨ë¸ ì‹¤í–‰
    private func loadRealESRGANModel(completion: @escaping (Bool) -> Void) {
        if realesrganX2Model != nil {
            completion(true)
            return
        }
        
        // ë¡œì»¬ íŒŒì¼ í™•ì¸
        if let modelURL = getLocalModelURL(modelName: "realesrgan_x2plus") {
            do {
                let config = MLModelConfiguration()
                config.computeUnits = .all
                realesrganX2Model = try MLModel(contentsOf: modelURL, configuration: config)
                print("âœ… Real-ESRGAN x2 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                completion(true)
                return
            } catch {
                print("âŒ Real-ESRGAN x2 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: \(error)")
            }
        }
        
        // ëª¨ë¸ì´ ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ
        ensureModelDownloaded(modelName: "realesrgan_x2plus", url: realesrganURL) { [weak self] success in
            guard let self = self, success else {
                completion(false)
                return
            }
            
            if let modelURL = self.getLocalModelURL(modelName: "realesrgan_x2plus") {
                do {
                    let config = MLModelConfiguration()
                    config.computeUnits = .all
                    self.realesrganX2Model = try MLModel(contentsOf: modelURL, configuration: config)
                    print("âœ… Real-ESRGAN x2 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                    completion(true)
                } catch {
                    print("âŒ Real-ESRGAN x2 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: \(error)")
                    completion(false)
                }
            } else {
                completion(false)
            }
        }
    }
    
    private func loadRealESRGANModelSync() -> MLModel? {
        if let modelURL = getLocalModelURL(modelName: "realesrgan_x2plus") {
            do {
                let config = MLModelConfiguration()
                config.computeUnits = .all
                return try MLModel(contentsOf: modelURL, configuration: config)
            } catch {
                print("âŒ Real-ESRGAN x2 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: \(error)")
            }
        }
        return nil
    }
    
    // ëª¨ë¸ì˜ í—ˆìš©ë˜ëŠ” ì…ë ¥ í¬ê¸° í™•ì¸
    private func getAllowedInputSize(for model: MLModel) -> CGSize? {
        let modelDescription = model.modelDescription
        let inputDescription = modelDescription.inputDescriptionsByName
        
        guard let firstInput = inputDescription.values.first else {
            return nil
        }
        
        // Image íƒ€ì…ì¸ ê²½ìš° í¬ê¸° ì œì•½ í™•ì¸
        // CoreML ëª¨ë¸ì˜ ì…ë ¥ ì œì•½ í™•ì¸ ì‹œë„
        if firstInput.type == .image {
            // ì¼ë°˜ì ìœ¼ë¡œ Real-ESRGAN ëª¨ë¸ì€ 512x512 ë˜ëŠ” 1024x1024ë¥¼ í—ˆìš©
            // ì—ëŸ¬ ë©”ì‹œì§€ì—ì„œ í—ˆìš©ë˜ì§€ ì•ŠëŠ” í¬ê¸°ë¥¼ í™•ì¸í–ˆìœ¼ë¯€ë¡œ, ë” ì‘ì€ í¬ê¸°ë¡œ ì‹œë„
            // ì¼ë°˜ì ìœ¼ë¡œ 512x512 ë˜ëŠ” 1024x1024ê°€ ì•ˆì „í•œ í¬ê¸°
            return CGSize(width: 512, height: 512)
        }
        
        return nil
    }
    
    // ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì´ í—ˆìš©í•˜ëŠ” í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    // Real-ESRGAN ëª¨ë¸ì€ ë³´í†µ ì •ì‚¬ê°í˜• í¬ê¸°ë‚˜ 64ì˜ ë°°ìˆ˜ë¥¼ ìš”êµ¬
    private func resizeImageToAllowedSize(_ image: UIImage, allowedSize: CGSize) -> UIImage? {
        let imageSize = image.size
        
        // ì •ì‚¬ê°í˜• í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ì¼ë°˜ì ìœ¼ë¡œ Real-ESRGANì€ ì •ì‚¬ê°í˜•ì„ ì„ í˜¸)
        // 64ì˜ ë°°ìˆ˜ë¡œ ë§ì¶”ê¸°
        let maxDimension = max(imageSize.width, imageSize.height)
        var targetSize: CGFloat = 512.0
        
        // 64ì˜ ë°°ìˆ˜ë¡œ ê°€ì¥ ê°€ê¹Œìš´ í¬ê¸° ì„ íƒ
        if maxDimension <= 256 {
            targetSize = 256
        } else if maxDimension <= 512 {
            targetSize = 512
        } else if maxDimension <= 768 {
            targetSize = 512 // 768ì€ í—ˆìš©ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ 512 ì‚¬ìš©
        } else if maxDimension <= 1024 {
            targetSize = 512 // ì•ˆì „í•˜ê²Œ 512 ì‚¬ìš©
        } else {
            targetSize = 512 // í° ì´ë¯¸ì§€ëŠ” 512ë¡œ ì œí•œ
        }
        
        // ì •ì‚¬ê°í˜•ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        let squareSize = CGSize(width: targetSize, height: targetSize)
        return resizeImage(image, to: squareSize)
    }
    
    private func runRealESRGAN(_ image: UIImage, scale: Int) -> UIImage? {
        // í•­ìƒ x2 ëª¨ë¸ ì‚¬ìš© (scale íŒŒë¼ë¯¸í„°ëŠ” í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
        guard let model = realesrganX2Model else {
            print("âŒ Real-ESRGAN ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            return nil
        }
        
        // ëª¨ë¸ì˜ ì…ë ¥/ì¶œë ¥ ì´ë¦„ í™•ì¸
        let modelDescription = model.modelDescription
        let inputDescription = modelDescription.inputDescriptionsByName
        let outputDescription = modelDescription.outputDescriptionsByName
        
        print("ğŸ“‹ Real-ESRGAN ëª¨ë¸ ì…ë ¥: \(inputDescription.keys.joined(separator: ", "))")
        print("ğŸ“‹ Real-ESRGAN ëª¨ë¸ ì¶œë ¥: \(outputDescription.keys.joined(separator: ", "))")
        
        // ì²« ë²ˆì§¸ ì…ë ¥/ì¶œë ¥ ì´ë¦„ ì‚¬ìš©
        guard let inputName = inputDescription.keys.first,
              let outputName = outputDescription.keys.first else {
            print("âŒ ëª¨ë¸ ì…ë ¥/ì¶œë ¥ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return nil
        }
        
        // ì¶œë ¥ description í™•ì¸
        if let outputDesc = outputDescription[outputName] {
            print("ğŸ“‹ ì¶œë ¥ íƒ€ì…: \(outputDesc.type)")
            if let imageConstraint = outputDesc.imageConstraint {
                print("ğŸ“‹ ì¶œë ¥ ì´ë¯¸ì§€ ì œì•½: \(imageConstraint)")
            }
        }
        
        // ëª¨ë¸ì˜ í—ˆìš©ë˜ëŠ” ì…ë ¥ í¬ê¸° í™•ì¸
        let originalSize = image.size
        var processedImage = image
        var needsResize = false
        
        // Real-ESRGAN ëª¨ë¸ì€ ì •ì‚¬ê°í˜• í¬ê¸°ë¥¼ ìš”êµ¬í•˜ë¯€ë¡œ í•­ìƒ ì •ì‚¬ê°í˜•ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        // ì›ë³¸ì´ ì •ì‚¬ê°í˜•ì´ ì•„ë‹ˆê±°ë‚˜ í—ˆìš© í¬ê¸°ë³´ë‹¤ í° ê²½ìš° ë¦¬ì‚¬ì´ì¦ˆ
        if let allowedSize = getAllowedInputSize(for: model) {
            print("ğŸ“ ëª¨ë¸ í—ˆìš© í¬ê¸°: \(allowedSize.width)x\(allowedSize.height)")
            print("ğŸ“ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: \(originalSize.width)x\(originalSize.height)")
            
            // ì •ì‚¬ê°í˜•ì´ ì•„ë‹ˆê±°ë‚˜ í—ˆìš© í¬ê¸°ë³´ë‹¤ í° ê²½ìš° ë¦¬ì‚¬ì´ì¦ˆ
            let isSquare = abs(originalSize.width - originalSize.height) < 1.0
            let isTooLarge = originalSize.width > allowedSize.width || originalSize.height > allowedSize.height
            
            if !isSquare || isTooLarge {
                needsResize = true
                guard let resized = resizeImageToAllowedSize(image, allowedSize: allowedSize) else {
                    print("âŒ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ì‹¤íŒ¨")
                    return nil
                }
                processedImage = resized
                print("ğŸ“ ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ í¬ê¸°: \(processedImage.size.width)x\(processedImage.size.height)")
            }
        }
        
        guard let pixelBuffer = imageToPixelBuffer(processedImage, size: processedImage.size) else {
            print("âŒ ì´ë¯¸ì§€ë¥¼ PixelBufferë¡œ ë³€í™˜ ì‹¤íŒ¨")
            return nil
        }
        
        do {
            // ëª¨ë¸ ì…ë ¥ ìƒì„± (ì‹¤ì œ ëª¨ë¸ì˜ ì…ë ¥ í˜•ì‹ì— ë§ì¶°ì•¼ í•¨)
            let input = try MLDictionaryFeatureProvider(dictionary: [inputName: MLFeatureValue(pixelBuffer: pixelBuffer)])
            
            // ëª¨ë¸ ì‹¤í–‰
            let prediction = try model.prediction(from: input)
            
            // ì¶œë ¥ ì¶”ì¶œ (ì‹¤ì œ ëª¨ë¸ì˜ ì¶œë ¥ í˜•ì‹ì— ë§ì¶°ì•¼ í•¨)
            guard let outputFeature = prediction.featureValue(for: outputName) else {
                print("âŒ ëª¨ë¸ ì¶œë ¥ featureë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ - ì¶œë ¥ ì´ë¦„: \(outputName)")
                print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì¶œë ¥: \(prediction.featureNames.joined(separator: ", "))")
                return nil
            }
            
            print("ğŸ“‹ ì¶œë ¥ feature íƒ€ì…: \(outputFeature.type)")
            
            var resultImage: UIImage?
            
            // ì¶œë ¥ì´ Image íƒ€ì…ì¸ ê²½ìš°
            if let outputPixelBuffer = outputFeature.imageBufferValue {
                resultImage = pixelBufferToImage(outputPixelBuffer)
            }
            // ì¶œë ¥ì´ MultiArray íƒ€ì…ì¸ ê²½ìš° (MLMultiArray -> UIImage ë³€í™˜ í•„ìš”)
            else if let multiArray = outputFeature.multiArrayValue {
                print("ğŸ“‹ ì¶œë ¥ì´ MultiArray íƒ€ì…ì…ë‹ˆë‹¤. shape: \(multiArray.shape.map { $0.intValue })")
                // MultiArrayë¥¼ UIImageë¡œ ë³€í™˜
                resultImage = multiArrayToRGBImage(multiArray)
                if resultImage == nil {
                    print("âŒ MultiArrayë¥¼ UIImageë¡œ ë³€í™˜ ì‹¤íŒ¨")
                    return nil
                }
            }
            // ë‹¤ë¥¸ íƒ€ì…ì¸ ê²½ìš°
            else {
                print("âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” ì¶œë ¥ íƒ€ì…: \(outputFeature.type)")
                return nil
            }
            
            guard let finalResultImage = resultImage else {
                print("âŒ ì¶œë ¥ì„ UIImageë¡œ ë³€í™˜ ì‹¤íŒ¨")
                return nil
            }
            
            // ì›ë³¸ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆê°€ í•„ìš”í•œ ê²½ìš° (auto enhance, reduce noise)
            if needsResize {
                guard let finalImage = resizeImage(finalResultImage, to: originalSize) else {
                    print("âŒ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ì›ë³¸ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ ì‹¤íŒ¨")
                    return nil
                }
                return finalImage
            }
            
            return finalResultImage
            
        } catch {
            print("âŒ Real-ESRGAN ëª¨ë¸ ì‹¤í–‰ ì‹¤íŒ¨: \(error.localizedDescription)")
            print("âŒ ì—ëŸ¬ ìƒì„¸: \(error)")
            return nil
        }
    }
    
    // ì´ë¯¸ì§€ ì €ì¥ í—¬í¼ í•¨ìˆ˜
    private func saveImage(_ image: UIImage, prefix: String) -> String? {
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let timestamp = Int(Date().timeIntervalSince1970 * 1000)
        let filename = "\(prefix)_\(timestamp).png"
        let fileURL = documentsPath.appendingPathComponent(filename)
        
        guard let imageData = image.pngData() else {
            return nil
        }
        
        do {
            try imageData.write(to: fileURL)
            return fileURL.path
        } catch {
            print("Failed to save image: \(error)")
            return nil
        }
    }
    
    // MARK: - ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ê´€ë¦¬
    private func getLocalModelURL(modelName: String) -> URL? {
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        
        // ì»´íŒŒì¼ëœ .mlmodelc íŒŒì¼ í™•ì¸ (ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸)
        let compiledModelPath = documentsPath.appendingPathComponent("models/\(modelName).mlmodelc")
        if FileManager.default.fileExists(atPath: compiledModelPath.path) {
            return compiledModelPath
        }
        
        // Bundleì—ì„œ í™•ì¸ (ì´ë¯¸ ì»´íŒŒì¼ë˜ì–´ ìˆìŒ)
        if let bundleURL = Bundle.main.url(forResource: modelName, withExtension: "mlmodelc") {
            return bundleURL
        }
        
        return nil
    }
    
    private func ensureModelDownloaded(modelName: String, url: String, completion: @escaping (Bool) -> Void) {
        // ì´ë¯¸ ë¡œì»¬ì— ìˆìœ¼ë©´ ë°”ë¡œ ë°˜í™˜
        if getLocalModelURL(modelName: modelName) != nil {
            sendProgress(modelName: modelName, progress: 1.0, status: "ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
            completion(true)
            return
        }
        
        sendProgress(modelName: modelName, progress: 0.0, status: "ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        
        guard let downloadURL = URL(string: url) else {
            sendProgress(modelName: modelName, progress: 0.0, status: "ë‹¤ìš´ë¡œë“œ URL ì˜¤ë¥˜")
            completion(false)
            return
        }
        
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let modelsDir = documentsPath.appendingPathComponent("models")
        let zipPath = modelsDir.appendingPathComponent("\(modelName).zip")
        let extractPath = modelsDir.appendingPathComponent(modelName)
        
        // ë””ë ‰í† ë¦¬ ìƒì„±
        try? FileManager.default.createDirectory(at: modelsDir, withIntermediateDirectories: true, attributes: nil)
        
        // ë‹¤ìš´ë¡œë“œ
        let task = URLSession.shared.downloadTask(with: downloadURL) { [weak self] tempURL, response, error in
            guard let self = self else {
                completion(false)
                return
            }
            
            if let error = error {
                print("âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: \(error.localizedDescription)")
                self.sendProgress(modelName: modelName, progress: 0.0, status: "ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: \(error.localizedDescription)")
                completion(false)
                return
            }
            
            guard let tempURL = tempURL else {
                self.sendProgress(modelName: modelName, progress: 0.0, status: "ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: ì„ì‹œ íŒŒì¼ ì—†ìŒ")
                completion(false)
                return
            }
            
            // zip íŒŒì¼ ì €ì¥
            do {
                try FileManager.default.moveItem(at: tempURL, to: zipPath)
                self.sendProgress(modelName: modelName, progress: 0.5, status: "ì••ì¶• í•´ì œ ì¤‘...")
                
                // zip í•´ì œ
                try self.unzipFile(at: zipPath, to: extractPath)
                
                // zip íŒŒì¼ ì‚­ì œ
                try? FileManager.default.removeItem(at: zipPath)
                
                // .mlmodelc íŒŒì¼ í™•ì¸
                let compiledModelPath = extractPath.appendingPathComponent("\(modelName).mlmodelc")
                
                guard FileManager.default.fileExists(atPath: compiledModelPath.path) else {
                    self.sendProgress(modelName: modelName, progress: 0.0, status: "ì••ì¶• í•´ì œ ì‹¤íŒ¨: .mlmodelc íŒŒì¼ ì—†ìŒ")
                    completion(false)
                    return
                }
                
                // ì»´íŒŒì¼ëœ .mlmodelc íŒŒì¼ì„ models ë””ë ‰í† ë¦¬ë¡œ ì´ë™
                let finalPath = modelsDir.appendingPathComponent("\(modelName).mlmodelc")
                try? FileManager.default.removeItem(at: finalPath)
                try FileManager.default.moveItem(at: compiledModelPath, to: finalPath)
                try? FileManager.default.removeItem(at: extractPath)
                
                self.sendProgress(modelName: modelName, progress: 1.0, status: "ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                completion(true)
            } catch {
                print("âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: \(error.localizedDescription)")
                self.sendProgress(modelName: modelName, progress: 0.0, status: "íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: \(error.localizedDescription)")
                completion(false)
            }
        }
        
        // ì§„í–‰ë„ ëª¨ë‹ˆí„°ë§
        let observation = task.progress.observe(\.fractionCompleted) { [weak self] progress, _ in
            guard let self = self else { return }
            let percent = progress.fractionCompleted * 0.5 // ë‹¤ìš´ë¡œë“œëŠ” 50%ê¹Œì§€
            self.sendProgress(modelName: modelName, progress: percent, status: "ë‹¤ìš´ë¡œë“œ ì¤‘... \(Int(percent * 100))%")
        }
        
        task.resume()
    }
    
    private func unzipFile(at zipPath: URL, to destinationPath: URL) throws {
        // SSZipArchiveë¥¼ ì‚¬ìš©í•œ zip í•´ì œ
        // ë””ë ‰í† ë¦¬ ìƒì„±
        try? FileManager.default.createDirectory(at: destinationPath, withIntermediateDirectories: true, attributes: nil)
        
        // SSZipArchiveë¡œ zip í•´ì œ
        var error: NSError?
        let success = SSZipArchive.unzipFile(
            atPath: zipPath.path,
            toDestination: destinationPath.path,
            preserveAttributes: true,
            overwrite: true,
            password: nil,
            error: &error,
            delegate: nil
        )
        
        if !success {
            let errorMessage = error?.localizedDescription ?? "ì••ì¶• í•´ì œ ì‹¤íŒ¨"
            throw NSError(domain: "UnzipError", code: -1, userInfo: [NSLocalizedDescriptionKey: errorMessage])
        }
    }
    
    private func copyModelToBundleIfNeeded(modelName: String, from sourceURL: URL) {
        // Bundleì€ ì½ê¸° ì „ìš©ì´ë¯€ë¡œ ì‹¤ì œë¡œëŠ” ë³µì‚¬í•  ìˆ˜ ì—†ìŒ
        // ëŒ€ì‹  Documents ë””ë ‰í† ë¦¬ì˜ ëª¨ë¸ì„ ì§ì ‘ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì • í•„ìš”
        // ì¼ë‹¨ ì´ í•¨ìˆ˜ëŠ” placeholderë¡œ ë‚¨ê²¨ë‘ 
    }
}

